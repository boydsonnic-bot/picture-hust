# Lá»™ trÃ¬nh há»c 8 tuáº§n (tá»« dá»… â†’ khÃ³) cho dá»± Ã¡n Computer Vision

**Má»¥c tiÃªu**: NÃ¢ng cáº¥p tá»« code phÃ¡t hiá»‡n contour cÆ¡ báº£n (`test02.py`) lÃªn há»‡ thá»‘ng phÃ¡t hiá»‡n khuyáº¿t táº­t tá»± Ä‘á»™ng (detection/classification) vá»›i Deep Learning.

**Time budget**: 
- Thá»© 2-6: 1h/ngÃ y Ã— 5 = 5h/tuáº§n
- Thá»© 7-CN: 3h/ngÃ y Ã— 2 = 6h/tuáº§n
- **Tá»•ng: ~10-11h/tuáº§n Ã— 8 tuáº§n = 80-88h**

**NguyÃªn táº¯c**: Kiáº¿n thá»©c tá»« dá»… â†’ khÃ³; má»—i tuáº§n vá»«a Ä‘á»c lÃ½ thuyáº¿t vá»«a code thá»±c hÃ nh.

---

## ğŸ“š PhÃ¢n tÃ­ch code hiá»‡n táº¡i (`test02.py`)

**Code báº¡n Ä‘ang cÃ³**:
```python
gray â†’ GaussianBlur â†’ Otsu threshold â†’ findContours â†’ boundingRect â†’ save
```

**Äiá»ƒm máº¡nh**: 
- Xá»­ lÃ½ áº£nh cÆ¡ báº£n (grayscale, blur, threshold)
- PhÃ¡t hiá»‡n contour vÃ  tÃ­nh area
- CLI arguments, save káº¿t quáº£

**Háº¡n cháº¿ (cáº§n nÃ¢ng cáº¥p)**:
- KhÃ´ng cÃ³ tiá»n xá»­ lÃ½ nÃ¢ng cao (CLAHE, morphology, adaptive threshold)
- ChÆ°a phÃ¢n loáº¡i (classify) contour lÃ  khuyáº¿t táº­t hay nhiá»…u
- ChÆ°a dÃ¹ng Deep Learning (CNN) Ä‘á»ƒ há»c feature tá»± Ä‘á»™ng
- ChÆ°a cÃ³ detection model (YOLO, Faster R-CNN) Ä‘á»ƒ Ä‘á»‹nh vá»‹ chÃ­nh xÃ¡c

---

## ğŸ—“ï¸ Lá»™ trÃ¬nh 8 tuáº§n (Easy â†’ Hard)

### **TUáº¦N 1-2: Classical Computer Vision (Ná»n táº£ng xá»­ lÃ½ áº£nh)**

**Má»¥c tiÃªu**: NÃ¢ng cáº¥p preprocessing pipeline (tiá»n xá»­ lÃ½ áº£nh tá»‘t hÆ¡n)

#### Tuáº§n 1: Adaptive Thresholding & CLAHE
- **Äá»c tá»« PDF** (ChÆ°Æ¡ng 1-2 hoáº·c pháº§n cÆ¡ báº£n): Python basics, NumPy, Matplotlib
- **Äá»c thÃªm (Google search)**:
  - `CLAHE OpenCV` (Contrast Limited Adaptive Histogram Equalization)
  - `Adaptive Threshold vs Otsu`
  - `Morphological operations erosion dilation`
- **Key concepts**:
  - **CLAHE**: TÄƒng contrast cá»¥c bá»™ (tá»‘t cho áº£nh X-ray cÃ³ Ä‘á»™ sÃ¡ng khÃ´ng Ä‘á»u)
  - **Adaptive Threshold**: Threshold Ä‘á»™ng theo vÃ¹ng (tá»‘t hÆ¡n Otsu khi áº£nh cÃ³ lighting khÃ´ng Ä‘á»“ng nháº¥t)
  - **Morphology (erosion/dilation/opening/closing)**: Loáº¡i bá» noise, lÃ m má»‹n contour

- **Code nÃ¢ng cáº¥p (3-4h)**:
  ```python
  # test02_v2.py - add CLAHE + adaptive threshold
  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
  enhanced = clahe.apply(gray)
  adaptive_thresh = cv2.adaptiveThreshold(enhanced, 255, 
                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                           cv2.THRESH_BINARY_INV, 11, 2)
  # Morphology
  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
  morph = cv2.morphologyEx(adaptive_thresh, cv2.MORPH_CLOSE, kernel)
  ```

- **Output**: So sÃ¡nh Otsu vs Adaptive + CLAHE side-by-side

#### Tuáº§n 2: Feature Engineering (Geometric features)
- **Äá»c thÃªm**:
  - `Contour features OpenCV` (area, perimeter, circularity, aspect ratio)
  - `Hu Moments invariant features`
- **Key concepts**:
  - **Geometric features**: Area, perimeter, circularity = 4Ï€Ã—area/perimeterÂ², aspect ratio = w/h
  - **Hu Moments**: Báº¥t biáº¿n vá»›i rotation, scale (dÃ¹ng Ä‘á»ƒ mÃ´ táº£ hÃ¬nh dáº¡ng)

- **Code nÃ¢ng cáº¥p (3-4h)**:
  ```python
  def extract_features(contour):
      area = cv2.contourArea(contour)
      perimeter = cv2.arcLength(contour, True)
      circularity = 4 * np.pi * area / (perimeter**2) if perimeter > 0 else 0
      x,y,w,h = cv2.boundingRect(contour)
      aspect_ratio = w / h if h > 0 else 0
      hu_moments = cv2.HuMoments(cv2.moments(contour)).flatten()
      return [area, perimeter, circularity, aspect_ratio] + list(hu_moments)
  ```

- **Output**: CSV file chá»©a features cá»§a má»—i contour, filter contour theo rule-based (vÃ­ dá»¥: circularity < 0.5 â†’ cÃ³ thá»ƒ lÃ  khuyáº¿t táº­t dáº¡ng crack)

**ğŸ“Œ Keywords tuáº§n 1-2**: `CLAHE`, `Adaptive Threshold`, `Morphology`, `Contour Features`, `Hu Moments`

---

### **TUáº¦N 3-4: Deep Learning Basics (CNN cÆ¡ báº£n cho Classification)**

**Má»¥c tiÃªu**: Há»c CNN Ä‘á»ƒ phÃ¢n loáº¡i áº£nh (OK vs NG) hoáº·c phÃ¢n loáº¡i tá»«ng contour

#### Tuáº§n 3: CNN Architecture & Transfer Learning
- **Äá»c tá»« PDF**:
  - **ChÆ°Æ¡ng 3: Linear Regression** (trang 49-59) â†’ hiá»ƒu Loss function (MSE, MAE), Gradient Descent, Regularization
  - **ChÆ°Æ¡ng 4-6: Neural Network basics, Backpropagation, CNN** (náº¿u cÃ³) â†’ hiá»ƒu Convolution, Pooling, Activation (ReLU)
  
- **Äá»c thÃªm**:
  - `CNN explained simple` (3Blue1Brown YouTube hoáº·c blog)
  - `Transfer Learning PyTorch/TensorFlow`
  - `ResNet MobileNet architecture`

- **Key concepts**:
  - **Convolution**: Kernel/filter trÃ­ch xuáº¥t feature tá»« áº£nh
    - Formula: `output_size = (input - kernel + 2Ã—padding) / stride + 1`
    - Receptive field: VÃ¹ng áº£nh mÃ  má»—i neuron "nhÃ¬n tháº¥y"
  - **Pooling**: MaxPooling/AvgPooling giáº£m kÃ­ch thÆ°á»›c spatial
  - **Transfer Learning**: DÃ¹ng pretrained model (ResNet, MobileNet) â†’ fine-tune trÃªn dataset nhá» cá»§a báº¡n
  - **Loss**: CrossEntropyLoss (classification), Binary CrossEntropy (binary classification)

- **Code (4-5h)**:
  ```python
  # classifier_v1.py - Binary classification (OK vs Defect)
  import torch
  import torchvision.models as models
  
  model = models.resnet18(pretrained=True)
  model.fc = torch.nn.Linear(model.fc.in_features, 2)  # 2 classes: OK, NG
  
  # Training loop (simplified)
  criterion = torch.nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
  ```

- **Output**: Model phÃ¢n loáº¡i áº£nh toÃ n bá»™ (full image) thÃ nh OK/NG vá»›i accuracy ~80-90%

#### Tuáº§n 4: Data Augmentation & Training
- **Äá»c tá»« PDF**:
  - **ChÆ°Æ¡ng Regularization** (trang 49-59): Dropout, L2 weight decay, BatchNorm, Early Stopping
  - **ChÆ°Æ¡ng Training & Optimization** (trang 27-35): Learning rate scheduling, Adam vs SGD

- **Äá»c thÃªm**:
  - `Data Augmentation for small dataset`
  - `imgaug albumentations library`
  - `Learning rate scheduler PyTorch`

- **Key concepts**:
  - **Augmentation**: Rotation (Â±10Â°), Horizontal flip, Brightness/Contrast, Noise (cáº©n tháº­n vá»›i vertical flip cho áº£nh X-ray)
  - **Regularization**: 
    - Dropout (0.3-0.5) á»Ÿ fully-connected layers
    - L2 weight decay (1e-4)
    - BatchNorm (sau Conv, trÆ°á»›c ReLU)
  - **LR Scheduler**: ReduceLROnPlateau (giáº£m LR khi val_loss khÃ´ng cáº£i thiá»‡n), CosineAnnealing

- **Code (4-5h)**:
  ```python
  import albumentations as A
  
  transform = A.Compose([
      A.Rotate(limit=15, p=0.5),
      A.HorizontalFlip(p=0.5),
      A.RandomBrightnessContrast(p=0.3),
      A.GaussNoise(p=0.2)
  ])
  
  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', 
                                                           factor=0.5, patience=5)
  ```

- **Output**: Model vá»›i augmentation + regularization, accuracy cáº£i thiá»‡n ~5-10%, training curve (loss/accuracy plot)

**ğŸ“Œ Keywords tuáº§n 3-4**: `CNN`, `Convolution`, `Pooling`, `Transfer Learning`, `ResNet`, `MobileNet`, `Data Augmentation`, `Dropout`, `Learning Rate Scheduler`

---

### **TUáº¦N 5-6: Object Detection (PhÃ¡t hiá»‡n & Äá»‹nh vá»‹ khuyáº¿t táº­t)**

**Má»¥c tiÃªu**: DÃ¹ng YOLO hoáº·c Faster R-CNN Ä‘á»ƒ phÃ¡t hiá»‡n vá»‹ trÃ­ khuyáº¿t táº­t (bounding box)

#### Tuáº§n 5: YOLO Basics & Labeling
- **Äá»c tá»« PDF**: 
  - Náº¿u cÃ³ chÆ°Æ¡ng Detection â†’ Ä‘á»c IoU, mAP, Anchor boxes
  - Náº¿u khÃ´ng cÃ³ â†’ Google search

- **Äá»c thÃªm**:
  - `YOLO object detection explained`
  - `YOLOv8 Ultralytics tutorial`
  - `LabelImg annotation tool`
  - `COCO dataset format`

- **Key concepts**:
  - **Object Detection**: Classify + Localize (bounding box)
  - **IoU (Intersection over Union)**: Metric Ä‘o overlap giá»¯a predicted box vÃ  ground truth
    - Formula: `IoU = Area(overlap) / Area(union)`
    - IoU > 0.5 â†’ good detection
  - **mAP (mean Average Precision)**: Metric tá»•ng há»£p cho detection (mAP@0.5, mAP@0.5:0.95)
  - **YOLO**: Single-stage detector (nhanh), chia áº£nh thÃ nh grid, má»—i cell dá»± Ä‘oÃ¡n bounding box + class
  - **Anchor boxes**: Predefined bounding box shapes (há»c tá»« dataset)

- **Code (5-6h)**:
  - Label ~50-100 áº£nh báº±ng LabelImg (format YOLO txt)
  - Train YOLOv8:
  ```python
  from ultralytics import YOLO
  
  model = YOLO('yolov8n.pt')  # nano model (nháº¹, nhanh)
  model.train(data='data.yaml', epochs=50, imgsz=640, batch=8)
  ```

- **Output**: Model detect bounding box cá»§a khuyáº¿t táº­t, mAP@0.5 ~60-70% (tÃ¹y data quality)

#### Tuáº§n 6: Model Comparison & Optimization
- **Äá»c thÃªm**:
  - `YOLO vs Faster R-CNN comparison`
  - `Model quantization INT8 FP16`
  - `ONNX export inference speed`

- **Key concepts**:
  - **YOLO**: Nhanh (real-time), accuracy trung bÃ¬nh
  - **Faster R-CNN**: Cháº­m hÆ¡n, accuracy cao hÆ¡n (two-stage)
  - **Model size**: YOLOv8n (nano) ~3MB, YOLOv8s (small) ~11MB, YOLOv8m (medium) ~26MB
  - **Inference speed**: FPS (frames per second) trÃªn CPU/GPU

- **Code (4-5h)**:
  - So sÃ¡nh YOLOv8n vs YOLOv8s
  - Export to ONNX:
  ```python
  model.export(format='onnx')  # for deployment
  ```
  - Test inference speed

- **Output**: BÃ¡o cÃ¡o so sÃ¡nh (mAP, FPS, model size), chá»n model phÃ¹ há»£p

**ğŸ“Œ Keywords tuáº§n 5-6**: `YOLO`, `Object Detection`, `IoU`, `mAP`, `Bounding Box`, `Anchor`, `LabelImg`, `ONNX`

---

### **TUáº¦N 7: Semantic Segmentation (NÃ¢ng cao - phÃ¢n Ä‘oáº¡n pixel-level)**

**Má»¥c tiÃªu**: DÃ¹ng U-Net Ä‘á»ƒ phÃ¢n Ä‘oáº¡n khuyáº¿t táº­t (chÃ­nh xÃ¡c hÆ¡n bounding box)

- **Äá»c thÃªm**:
  - `U-Net architecture explained`
  - `Semantic Segmentation vs Instance Segmentation`
  - `Dice Loss IoU metric segmentation`

- **Key concepts**:
  - **Semantic Segmentation**: Classify tá»«ng pixel (background vs defect)
  - **U-Net**: Encoder-Decoder architecture vá»›i skip connections (tá»‘t cho medical/industrial images)
  - **Dice Loss**: Loss function cho segmentation (xá»­ lÃ½ class imbalance tá»‘t)
    - Formula: `Dice = 2Ã—|Aâˆ©B| / (|A|+|B|)`
  - **IoU/Dice score**: Metric Ä‘Ã¡nh giÃ¡ segmentation

- **Code (5-6h)**:
  ```python
  # u_net.py (simplified)
  import segmentation_models_pytorch as smp
  
  model = smp.Unet(
      encoder_name="resnet34",
      encoder_weights="imagenet",
      in_channels=1,  # grayscale
      classes=1,       # binary segmentation
  )
  
  loss = smp.losses.DiceLoss(mode='binary')
  ```

- **Output**: Mask phÃ¢n Ä‘oáº¡n chÃ­nh xÃ¡c vÃ¹ng khuyáº¿t táº­t (pixel-level), Dice score ~0.75-0.85

**ğŸ“Œ Keywords tuáº§n 7**: `U-Net`, `Semantic Segmentation`, `Dice Loss`, `Pixel-wise Classification`, `Encoder-Decoder`

---

### **TUáº¦N 8: Deployment & System Integration**

**Má»¥c tiÃªu**: ÄÃ³ng gÃ³i model thÃ nh API/app, tá»‘i Æ°u inference speed

- **Äá»c tá»« PDF**:
  - **ChÆ°Æ¡ng Deployment** (náº¿u cÃ³): SavedModel, ONNX, TensorRT

- **Äá»c thÃªm**:
  - `FastAPI machine learning deployment`
  - `OpenVINO Intel optimization`
  - `Docker containerization ML model`

- **Key concepts**:
  - **Model export**: `.pt` (PyTorch), `.onnx` (cross-framework), `.engine` (TensorRT)
  - **Inference optimization**: 
    - Quantization (FP32 â†’ FP16/INT8) â†’ 2-4Ã— faster
    - Batch inference (process multiple images at once)
    - OpenVINO (Intel) / TensorRT (NVIDIA) for hardware acceleration
  - **API**: FastAPI/Flask serve model qua HTTP
  - **Docker**: Container hÃ³a app (model + dependencies)

- **Code (6-8h)**:
  ```python
  # api.py
  from fastapi import FastAPI, UploadFile
  import cv2
  import numpy as np
  from ultralytics import YOLO
  
  app = FastAPI()
  model = YOLO('best.pt')
  
  @app.post("/predict")
  async def predict(file: UploadFile):
      img = cv2.imdecode(np.frombuffer(await file.read(), np.uint8), cv2.IMREAD_COLOR)
      results = model(img)
      return {"boxes": results[0].boxes.xyxy.tolist()}
  ```

- **Output**: 
  - API endpoint nháº­n áº£nh, tráº£ vá» predictions
  - Docker image cháº¡y Ä‘Æ°á»£c trÃªn mÃ¡y khÃ¡c
  - BÃ¡o cÃ¡o tá»‘c Ä‘á»™ inference (ms/image)

**ğŸ“Œ Keywords tuáº§n 8**: `FastAPI`, `ONNX`, `TensorRT`, `OpenVINO`, `Quantization`, `Docker`, `Model Deployment`

---

## ğŸ“Š Tá»•ng káº¿t cÃ¡c mÃ´ hÃ¬nh cáº§n tÃ¬m hiá»ƒu (theo thá»© tá»± dá»… â†’ khÃ³)

| Tuáº§n | MÃ´ hÃ¬nh/Ká»¹ thuáº­t | Má»¥c Ä‘Ã­ch | Äá»™ khÃ³ |
|------|------------------|----------|--------|
| 1-2 | Classical CV (CLAHE, Morphology) | Preprocessing | â­ |
| 3-4 | **ResNet/MobileNet** (Transfer Learning) | Image Classification | â­â­ |
| 5-6 | **YOLOv8** (Object Detection) | Detect bounding box | â­â­â­ |
| 6 (optional) | **Faster R-CNN** | Detection accuracy cao hÆ¡n | â­â­â­â­ |
| 7 | **U-Net** (Semantic Segmentation) | PhÃ¢n Ä‘oáº¡n pixel-level | â­â­â­â­ |
| 7 (optional) | **Mask R-CNN** | Instance Segmentation | â­â­â­â­â­ |

---

## ğŸ”‘ Key Concepts cáº§n master (Google search keywords)

### Week 1-2 (Classical CV)
- `CLAHE contrast enhancement`
- `Otsu vs Adaptive Threshold`
- `Morphological operations OpenCV`
- `Contour features aspect ratio circularity`

### Week 3-4 (CNN Basics)
- `Convolution explained`
- `Receptive field CNN`
- `Transfer Learning fine-tuning`
- `Data Augmentation techniques`
- `Dropout BatchNorm Regularization`
- `Learning rate scheduler PyTorch`

### Week 5-6 (Object Detection)
- `YOLO architecture how it works`
- `IoU calculation object detection`
- `mAP metric explained`
- `Anchor boxes YOLO`
- `Non-Maximum Suppression NMS`

### Week 7 (Segmentation)
- `U-Net architecture skip connections`
- `Dice Loss vs BCE Loss`
- `Semantic vs Instance Segmentation`

### Week 8 (Deployment)
- `ONNX model export`
- `Model quantization FP16 INT8`
- `FastAPI machine learning tutorial`
- `Docker containerize ML model`

---

## ğŸ’¡ Tips Ä‘á»ƒ khÃ´ng bá»‹ ngá»™p

1. **Má»—i tuáº§n chá»‰ focus 1 topic chÃ­nh** (vÃ­ dá»¥: tuáº§n 3 = CNN basics, Ä‘á»«ng nháº£y sang YOLO)
2. **Code ngay sau khi Ä‘á»c lÃ½ thuyáº¿t** (30 phÃºt Ä‘á»c â†’ 30 phÃºt code)
3. **LÆ°u code + notes vÃ o Git** (commit má»—i tuáº§n Ä‘á»ƒ theo dÃµi progress)
4. **Äá»c PDF chÆ°Æ¡ng tÆ°Æ¡ng á»©ng trÆ°á»›c, sau Ä‘Ã³ Google search chi tiáº¿t**
5. **Æ¯u tiÃªn practical (code) hÆ¡n theory sÃ¢u** (vÃ­ dá»¥: hiá»ƒu cÃ¡ch dÃ¹ng YOLO > hiá»ƒu toÃ¡n Ä‘áº±ng sau YOLO)

---

## ğŸ“ Daily Schedule Template

**Thá»© 2-6 (1h/ngÃ y)**:
- 20 phÃºt: Äá»c lÃ½ thuyáº¿t (PDF + blog)
- 30 phÃºt: Code/experiment
- 10 phÃºt: Note láº¡i key points + commit code

**Thá»© 7-CN (3h/ngÃ y)**:
- 1h: Äá»c lÃ½ thuyáº¿t sÃ¢u hÆ¡n (paper, tutorial)
- 1.5h: Code project chÃ­nh (train model, test)
- 30 phÃºt: Review tuáº§n + chuáº©n bá»‹ tuáº§n sau

---

## ğŸ¯ Deliverables cuá»‘i 8 tuáº§n

1. âœ… **Preprocessing pipeline** nÃ¢ng cáº¥p (CLAHE + Adaptive Threshold + Morphology)
2. âœ… **Classifier** (ResNet/MobileNet) phÃ¢n loáº¡i OK/NG vá»›i accuracy >85%
3. âœ… **Detector** (YOLOv8) phÃ¡t hiá»‡n bounding box vá»›i mAP@0.5 >70%
4. âœ… **(Optional)** **Segmentation model** (U-Net) vá»›i Dice >0.75
5. âœ… **API deployment** (FastAPI) + Docker container
6. âœ… **BÃ¡o cÃ¡o so sÃ¡nh** cÃ¡c mÃ´ hÃ¬nh (accuracy, speed, size)

---

**Next step**: Báº¯t Ä‘áº§u tuáº§n 1 â†’ upgrade `test02.py` vá»›i CLAHE + Adaptive Threshold. Báº¡n muá»‘n tÃ´i táº¡o file `test02_v2.py` máº«u khÃ´ng?
